# Vector Database Implementation trong PCM-WebApp

## ğŸ“‹ Tá»•ng quan

Vector Database Ä‘Æ°á»£c tÃ­ch há»£p vÃ o PCM-WebApp Ä‘á»ƒ cung cáº¥p kháº£ nÄƒng semantic search cho AI chat logs. Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng hoÃ n toÃ n trÃªn trÃ¬nh duyá»‡t sá»­ dá»¥ng IndexedDB Ä‘á»ƒ storage vÃ  TensorFlow.js (hoáº·c fallback text-based similarity) cho embedding generation.

---

## ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PCM-WebApp Frontend                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AI Chat Logs Page (UI)                                â”‚
â”‚  â”œâ”€â”€ Semantic Search Input                             â”‚
â”‚  â”œâ”€â”€ Search Results Display                            â”‚
â”‚  â””â”€â”€ Vector Statistics                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AI Chat Logger Service                                â”‚
â”‚  â”œâ”€â”€ Auto message indexing                             â”‚
â”‚  â”œâ”€â”€ Search API                                        â”‚
â”‚  â””â”€â”€ Statistics API                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Vector Database Service                               â”‚
â”‚  â”œâ”€â”€ Vector CRUD operations                            â”‚
â”‚  â”œâ”€â”€ Similarity search                                 â”‚
â”‚  â””â”€â”€ IndexedDB management                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Vector Embedding Service                              â”‚
â”‚  â”œâ”€â”€ TensorFlow.js (Universal Sentence Encoder)       â”‚
â”‚  â”œâ”€â”€ Fallback text-based similarity                   â”‚
â”‚  â””â”€â”€ Embedding cache                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Browser Storage Layer                                 â”‚
â”‚  â”œâ”€â”€ IndexedDB (Vector storage)                        â”‚
â”‚  â”œâ”€â”€ IndexedDB (Chat logs)                            â”‚
â”‚  â””â”€â”€ Memory cache                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u trÃºc file vÃ  chá»©c nÄƒng

### 1. **VectorEmbeddingService.js**

**Location**: `/apps/pcm-webapp/public/js/modules/ai/services/VectorEmbeddingService.js`

**Chá»©c nÄƒng**: Táº¡o vector embeddings tá»« text input

**Key Components**:

```javascript
class VectorEmbeddingService {
  // Line 6-13: Configuration vÃ  cache setup
  constructor() {
    this.model = null;
    this.modelType = "browser"; // 'browser', 'api', hoáº·c 'fallback'
    this.isInitialized = false;
    this.cache = new Map(); // LRU cache cho embeddings
    this.maxCacheSize = 1000;
  }

  // Line 18-45: Initialization vá»›i fallback handling
  async initialize(options = {}) {
    // Cá»‘ gáº¯ng load TensorFlow.js model
    // Náº¿u fail â†’ chuyá»ƒn sang fallback mode
  }

  // Line 42-90: Dynamic script loading
  async initializeBrowserModel() {
    // Load TensorFlow.js tá»« CDN
    // Load Universal Sentence Encoder
    // Fallback náº¿u network fail
  }

  // Line 148-196: Fallback embedding (text-based)
  embedWithFallback(text) {
    // TF-IDF style vector generation
    // 64-dimensional vectors
    // Word frequency + semantic features
  }
}
```

**Embedding Methods**:

- **Browser Model**: 512D vectors tá»« Universal Sentence Encoder
- **API Model**: External API calls (placeholder)
- **Fallback Model**: 64D vectors tá»« text analysis

---

### 2. **VectorDatabaseService.js**

**Location**: `/apps/pcm-webapp/public/js/modules/ai/services/VectorDatabaseService.js`

**Chá»©c nÄƒng**: Quáº£n lÃ½ vector storage vÃ  similarity search

**IndexedDB Schema**:

```javascript
// Line 45-58: Database setup
const store = db.createObjectStore("vectors", { keyPath: "id" });
store.createIndex("type", "type", { unique: false });
store.createIndex("sessionId", "sessionId", { unique: false });
store.createIndex("timestamp", "timestamp", { unique: false });
```

**Vector Document Structure**:

```javascript
// Line 77-85: Vector document format
const vectorDoc = {
  id: "session_123_user_message_1699123456789",
  vector: [0.1, 0.2, 0.3, ...], // 512D hoáº·c 64D array
  text: "User's actual message content",
  type: "user_message" | "ai_response",
  metadata: {
    sessionId: "session_123",
    timestamp: "2023-11-04T10:30:45.123Z",
    provider: "openai" // optional
  },
  dimension: 512 // hoáº·c 64
};
```

**Core Operations**:

```javascript
// Line 65-96: Add vector
async addVector(data) {
  const vector = await vectorEmbeddingService.embed(text);
  // Store in IndexedDB
}

// Line 115-168: Similarity search
async search(query, options = {}) {
  const queryVector = await vectorEmbeddingService.embed(query);
  const allVectors = await this.getAllVectors();

  // Calculate cosine similarity
  for (const doc of allVectors) {
    const similarity = vectorEmbeddingService.cosineSimilarity(
      queryVector, doc.vector
    );
  }

  return results.sort((a, b) => b.similarity - a.similarity);
}
```

---

### 3. **AIChatLogger.js** (Enhanced)

**Location**: `/apps/pcm-webapp/public/js/modules/ai/services/AIChatLogger.js`

**Vector Integration**:

```javascript
// Line 7: Import vector database
import vectorDatabaseService from "./VectorDatabaseService.js";

// Line 20-34: Vector DB initialization
async initializeVectorDB() {
  await vectorDatabaseService.initialize();
  this.isVectorDBInitialized = true;
}

// Line 125, 146: Auto-indexing messages
logAIResponse(response, provider) {
  // Save to regular IndexedDB
  this.saveLogEntry(logEntry);

  // Index in vector database for semantic search
  this.indexMessageInVectorDB(logEntry);
}

// Line 180-230: Vector indexing logic
async indexMessageInVectorDB(logEntry) {
  const content = logEntry.content || logEntry.response;

  // Skip non-text content vÃ  session control messages
  const skipTypes = ['session_start', 'session_end', 'function_call', 'function_result'];
  if (skipTypes.includes(logEntry.type)) return;

  // Create vector data
  const vectorData = {
    id: `${logEntry.sessionId}_${logEntry.type}_${Date.now()}`,
    text: content.substring(0, 1000), // Limit for performance
    type: logEntry.type,
    metadata: { sessionId, timestamp, provider }
  };

  await vectorDatabaseService.addVector(vectorData);
}

// Line 235-256: Search API
async searchMessages(query, options = {}) {
  return await vectorDatabaseService.search(query, options);
}
```

---

### 4. **AIChatLogsPage.js** (UI Integration)

**Location**: `/apps/pcm-webapp/public/js/modules/ai/pages/AIChatLogsPage.js`

**UI Components**:

```javascript
// Line 196-256: Semantic search UI
createVectorSearchSection() {
  // Search input box
  // Search results container
  // Vector statistics display
}

// Line 857-936: Search handling
async performVectorSearch() {
  const query = searchInput.value.trim();

  // Call vector search
  const results = await aiChatLogger.searchMessages(query, {
    limit: 10,
    threshold: 0.2
  });

  // Render results vá»›i similarity scores
  results.forEach(result => {
    const similarity = Math.round(result.similarity * 100);
    // Display result item vá»›i click-to-highlight
  });
}

// Line 973-998: Highlight search results
async highlightSearchResult(result) {
  const sessionId = result.metadata.sessionId;
  await this.selectSession(sessionId);

  // Find vÃ  highlight matching log entry
  logEntries.forEach(entry => {
    if (logContent.includes(result.text.substring(0, 50))) {
      entry.style.backgroundColor = '#fff3cd';
      entry.scrollIntoView({ behavior: 'smooth' });
    }
  });
}
```

---

## ğŸš€ Workflow hoáº¡t Ä‘á»™ng

### 1. **Message Logging & Indexing**

```
User sends message â†’ AIPanel.handleSendMessage()
                  â†“
              aiChatLogger.logMessage()
                  â†“
              Save to IndexedDB (chat logs)
                  â†“
              indexMessageInVectorDB()
                  â†“
              Generate embedding
                  â†“
              Store vector in IndexedDB (vectors)
```

**Source Reference**:

- `AIPanel.js:351` - User message logging
- `AIPanel.js:505, 547` - AI response logging
- `AIChatLogger.js:146, 125` - Auto vector indexing

### 2. **Semantic Search Process**

```
User enters search query â†’ UI.performVectorSearch()
                        â†“
                    Generate query embedding
                        â†“
                    Load all vectors from IndexedDB
                        â†“
                    Calculate cosine similarity
                        â†“
                    Sort by similarity score
                        â†“
                    Display results vá»›i click-to-highlight
```

**Source Reference**:

- `AIChatLogsPage.js:878` - Search initiation
- `VectorDatabaseService.js:130` - Query embedding
- `VectorEmbeddingService.js:133-153` - Cosine similarity calculation

### 3. **Embedding Generation**

```
Text input â†’ VectorEmbeddingService.embed()
           â†“
       Check cache first
           â†“
       Browser Model (TensorFlow.js)
           â†“ (if fails)
       Fallback Model (text-based)
           â†“
       Cache result vÃ  return vector
```

**Source Reference**:

- `VectorEmbeddingService.js:108` - Cache check
- `VectorEmbeddingService.js:115-123` - Model routing
- `VectorEmbeddingService.js:148-196` - Fallback implementation

---

## ğŸ”§ Cáº¥u hÃ¬nh vÃ  Tuning

### 1. **Vector Dimensions**

```javascript
// TensorFlow.js Universal Sentence Encoder
const BROWSER_EMBEDDING_DIM = 512;

// Fallback text-based embeddings
const FALLBACK_EMBEDDING_DIM = 64;
```

### 2. **Search Parameters**

```javascript
// Default search options
const searchOptions = {
  limit: 10, // Max results
  threshold: 0.2, // Minimum similarity (0-1)
  type: null, // Filter by log type
  sessionId: null, // Filter by session
};
```

### 3. **Cache Configuration**

```javascript
// VectorEmbeddingService.js:12
this.maxCacheSize = 1000; // LRU cache size

// Text length limit for performance
const maxTextLength = 1000; // AIChatLogger.js:210
```

### 4. **Fallback Text Features**

```javascript
// VectorEmbeddingService.js:156-163
const features = [
  "question",
  "answer",
  "help",
  "problem",
  "solution",
  "error",
  "function",
  "code",
  "user",
  "system",
  "data",
  "file",
  "create",
  "delete",
  "update",
  "search",
  // ... semantic keywords for similarity
];
```

---

## ğŸ§ª Testing vÃ  Debugging

### 1. **Vector Service Status**

```javascript
// Check embedding service status
const status = vectorEmbeddingService.getStatus();
console.log(status);
// { isInitialized: true, modelType: 'browser', cacheSize: 45 }

// Check database stats
const stats = await aiChatLogger.getVectorStats();
console.log(stats);
// { totalVectors: 123, typeDistribution: {...}, embeddingServiceStatus: {...} }
```

### 2. **Manual Vector Operations**

```javascript
// Direct embedding test
const vector = await vectorEmbeddingService.embed("Hello world");
console.log(vector.length); // 512 or 64

// Direct search test
const results = await vectorDatabaseService.search("greeting", {
  threshold: 0.3,
});
console.log(results.map((r) => ({ text: r.text, similarity: r.similarity })));
```

### 3. **Performance Monitoring**

```javascript
// Check cache hit rate
console.log(`Cache size: ${vectorEmbeddingService.cache.size}`);

// Monitor search performance
console.time("vectorSearch");
await aiChatLogger.searchMessages(query);
console.timeEnd("vectorSearch");
```

---

## âš ï¸ Offline Capability Analysis

### âœ… **HoÃ n toÃ n Offline - CÃ“ THá»‚**

**Äiá»u kiá»‡n**:

1. TensorFlow.js libraries Ä‘Ã£ cached trong browser
2. Hoáº·c fallback mode (khÃ´ng cáº§n external dependencies)

### ğŸ“‹ **Setup cho mÃ´i trÆ°á»ng Offline**

#### Option 1: Pre-cache TensorFlow.js

```javascript
// ThÃªm vÃ o HTML trÆ°á»›c khi offline
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder@1.3.3/dist/universal-sentence-encoder.min.js"></script>
```

#### Option 2: Local TensorFlow.js files

```bash
# Download vÃ  host locally
wget https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js
wget https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder@1.3.3/dist/universal-sentence-encoder.min.js

# Update script URLs trong VectorEmbeddingService.js:47,53
```

#### Option 3: Pure Offline (Fallback Only)

```javascript
// Force fallback mode - khÃ´ng cáº§n TensorFlow.js
await vectorEmbeddingService.initialize({ modelType: "fallback" });
```

### ğŸ¯ **Offline Performance**

| Mode              | Quality | Offline Ready    | Dependencies |
| ----------------- | ------- | ---------------- | ------------ |
| **TensorFlow.js** | 95%     | âš ï¸ Cáº§n pre-cache | External CDN |
| **Fallback**      | 65%     | âœ… HoÃ n toÃ n     | KhÃ´ng        |

### ğŸ“± **Storage Requirements (Offline)**

```
IndexedDB Storage:
â”œâ”€â”€ Chat Logs DB: ~1-5MB (cho 1000 messages)
â”œâ”€â”€ Vector DB: ~2-10MB (tÃ¹y embedding dimension)
â””â”€â”€ Browser Cache: ~20MB (TensorFlow.js model)
```

### ğŸ”§ **Offline Setup Script**

```javascript
// Offline initialization script
async function initOfflineVectorDB() {
  try {
    // Try TensorFlow.js first (if cached)
    await vectorEmbeddingService.initialize({ modelType: "browser" });
    console.log("âœ… Offline with TensorFlow.js");
  } catch (error) {
    // Fallback to text-based similarity
    await vectorEmbeddingService.initialize({ modelType: "fallback" });
    console.log("âš ï¸ Offline with fallback mode");
  }
}
```

---

## ğŸ“Š **Káº¿t luáº­n**

### âœ… **CÃ“ THá»‚ cháº¡y hoÃ n toÃ n offline**

1. **Fallback mode**: LuÃ´n hoáº¡t Ä‘á»™ng offline vá»›i text-based similarity (~65% accuracy)
2. **TensorFlow.js mode**: Hoáº¡t Ä‘á»™ng offline náº¿u libraries Ä‘Ã£ cached (~95% accuracy)
3. **IndexedDB storage**: HoÃ n toÃ n local, khÃ´ng cáº§n network

### ğŸ¯ **Khuyáº¿n nghá»‹ cho Production Offline**

1. **Pre-cache TensorFlow.js** trong app startup
2. **Implement service worker** Ä‘á»ƒ cache model files
3. **Use hybrid approach**: TensorFlow.js + fallback
4. **Monitor storage usage** vÃ  implement cleanup strategies

Vector Database trong PCM-WebApp Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ hoáº¡t Ä‘á»™ng robust trong má»i mÃ´i trÆ°á»ng, tá»« online high-performance Ä‘áº¿n offline basic functionality.

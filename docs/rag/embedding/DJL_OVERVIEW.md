# DJL (Deep Java Library) - Tá»•ng quan vÃ  HÆ°á»›ng dáº«n

## ğŸ“š Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [Kiáº¿n trÃºc](#kiáº¿n-trÃºc)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
- [API Reference](#api-reference)
- [Troubleshooting](#troubleshooting)
- [TÃ i nguyÃªn](#tÃ i-nguyÃªn)

---

## ğŸ¯ Giá»›i thiá»‡u

### DJL lÃ  gÃ¬?

**Deep Java Library (DJL)** lÃ  má»™t framework deep learning mÃ£ nguá»“n má»Ÿ dÃ nh cho Java, Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi AWS. DJL cung
cáº¥p:

- âœ… **API Java native**: KhÃ´ng cáº§n Python, hoÃ n toÃ n Java
- âœ… **Multi-engine**: Há»— trá»£ nhiá»u backend (PyTorch, TensorFlow, ONNX Runtime, MXNet)
- âœ… **Production-ready**: Tá»‘i Æ°u cho mÃ´i trÆ°á»ng production
- âœ… **Offline-first**: Cháº¡y hoÃ n toÃ n offline sau khi download model
- âœ… **Cross-platform**: Windows, macOS, Linux

### Táº¡i sao chá»n DJL cho Embeddings?

| Äáº·c Ä‘iá»ƒm        | DJL                     | Python (sentence-transformers) |
|-----------------|-------------------------|--------------------------------|
| **Tá»‘c Ä‘á»™**      | âš¡ Nhanh (JVM optimized) | ğŸ¢ Cháº­m hÆ¡n                    |
| **Memory**      | ğŸ’š Hiá»‡u quáº£             | ğŸ’› Tá»‘n memory hÆ¡n              |
| **Deployment**  | âœ… Single JAR            | âŒ Cáº§n Python runtime           |
| **Integration** | âœ… Trá»±c tiáº¿p trong Java  | âŒ Cáº§n bridge/API               |
| **Offline**     | âœ… HoÃ n toÃ n offline     | âœ… CÃ³ thá»ƒ offline               |
| **Production**  | âœ… Enterprise-ready      | ğŸ’› Cáº§n setup phá»©c táº¡p          |

---

## ğŸ—ï¸ Kiáº¿n trÃºc

### Kiáº¿n trÃºc tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PCM Desktop Application                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DJLEmbeddingService (Service Layer)         â”‚
â”‚  â€¢ Text â†’ Embeddings conversion                         â”‚
â”‚  â€¢ Model management                                      â”‚
â”‚  â€¢ Caching & optimization                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ONNX Runtime   â”‚              â”‚  HuggingFace         â”‚
â”‚                  â”‚              â”‚  Tokenizer           â”‚
â”‚  â€¢ Model         â”‚              â”‚                      â”‚
â”‚    inference     â”‚              â”‚  â€¢ Text â†’ Tokens     â”‚
â”‚  â€¢ Optimization  â”‚              â”‚  â€¢ Vocab mapping     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Sentence-Transformers Model                 â”‚
â”‚                   (ONNX Format)                          â”‚
â”‚                                                           â”‚
â”‚  â€¢ model.onnx        - Neural network weights            â”‚
â”‚  â€¢ tokenizer.json    - Tokenization config               â”‚
â”‚  â€¢ config.json       - Model configuration               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow hoáº¡t Ä‘á»™ng

```
User Input: "How to validate customers?"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Tokenization                â”‚
â”‚     Text â†’ Token IDs            â”‚
â”‚     [101, 2129, 2000, ...]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ONNX Inference              â”‚
â”‚     Token IDs â†’ Hidden States   â”‚
â”‚     Shape: [1, seq_len, 384]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Mean Pooling                â”‚
â”‚     Average token embeddings    â”‚
â”‚     Shape: [384]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. L2 Normalization            â”‚
â”‚     Normalize to unit vector    â”‚
â”‚     Final: float[384]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. Tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)

```bash
# Download DJL libraries vÃ  model
./scripts/setup-embeddings-djl.sh

# Build project
./scripts/build.sh
```

### 2. Thá»§ cÃ´ng

#### BÆ°á»›c 1: Download DJL JARs

Download cÃ¡c JARs sau vÃ o `lib/rag/`:

```bash
cd lib/rag

# DJL API (Core)
curl -LO https://repo1.maven.org/maven2/ai/djl/api/0.35.0/api-0.35.0.jar

# ONNX Runtime Engine
curl -LO https://repo1.maven.org/maven2/ai/djl/onnxruntime/onnxruntime-engine/0.35.0/onnxruntime-engine-0.35.0.jar

# HuggingFace Tokenizers
curl -LO https://repo1.maven.org/maven2/ai/djl/huggingface/tokenizers/0.35.0/tokenizers-0.35.0.jar

# ONNX Runtime (Backend)
curl -LO https://repo1.maven.org/maven2/com/microsoft/onnxruntime/onnxruntime/1.23.2/onnxruntime-1.23.2.jar
```

#### BÆ°á»›c 2: Download Model

```bash
# Táº¡o thÆ° má»¥c model
mkdir -p data/models/all-MiniLM-L6-v2
cd data/models/all-MiniLM-L6-v2

# Download model files
curl -LO "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/model.onnx"
curl -LO "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer.json"
curl -LO "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json"
```

#### BÆ°á»›c 3: Build

```bash
./scripts/build.sh
```

### 3. Kiá»ƒm tra cÃ i Ä‘áº·t

```bash
# Liá»‡t kÃª JARs
ls -lh lib/rag/*.jar

# Káº¿t quáº£ mong Ä‘á»£i:
# api-0.35.0.jar              (~900 KB)
# onnxruntime-engine-0.35.0.jar  (~56 KB)
# tokenizers-0.35.0.jar         (~18 MB)
# onnxruntime-1.23.2.jar        (~72 MB)
```

---

## ğŸ’» Sá»­ dá»¥ng

### Basic Usage

```java
import com.noteflix.pcm.rag.embedding.DJLEmbeddingService;
import com.noteflix.pcm.rag.embedding.EmbeddingService;

// Khá»Ÿi táº¡o service
EmbeddingService embeddings = new DJLEmbeddingService(
    "data/models/all-MiniLM-L6-v2"
);

// Táº¡o embedding cho má»™t text
String text = "How to validate customer information?";
float[] vector = embeddings.embed(text);

System.out.println("Dimension: " + vector.length);  // 384
System.out.println("First values: " + Arrays.toString(
    Arrays.copyOf(vector, 5)
));

// Cleanup
((DJLEmbeddingService) embeddings).close();
```

### Batch Processing

```java
// Embed nhiá»u texts cÃ¹ng lÃºc
String[] texts = {
    "How to validate customer information?",
    "Steps to verify user data",
    "Customer verification process"
};

float[][] embeddings = embeddingService.embedBatch(texts);

// embeddings.length = 3
// embeddings[0].length = 384
```

### Semantic Similarity

```java
// TÃ­nh cosine similarity
public float cosineSimilarity(float[] v1, float[] v2) {
    double dotProduct = 0.0;
    for (int i = 0; i < v1.length; i++) {
        dotProduct += v1[i] * v2[i];
    }
    return (float) dotProduct;  // Already normalized
}

// Sá»­ dá»¥ng
float[] emb1 = embeddings.embed("validate customer");
float[] emb2 = embeddings.embed("verify user");
float[] emb3 = embeddings.embed("prepare dinner");

float sim12 = cosineSimilarity(emb1, emb2);  // ~0.85 (cao - tÆ°Æ¡ng tá»±)
float sim13 = cosineSimilarity(emb1, emb3);  // ~0.12 (tháº¥p - khÃ¡c nhau)

System.out.printf("Similarity (1-2): %.3f%n", sim12);
System.out.printf("Similarity (1-3): %.3f%n", sim13);
```

### Production Usage vá»›i Cache

```java
public class CachedEmbeddingService implements EmbeddingService {
    private final EmbeddingService delegate;
    private final Map<String, float[]> cache = new ConcurrentHashMap<>();
    
    public CachedEmbeddingService(EmbeddingService delegate) {
        this.delegate = delegate;
    }
    
    @Override
    public float[] embed(String text) {
        return cache.computeIfAbsent(text, delegate::embed);
    }
    
    // ... other methods
}

// Usage
EmbeddingService base = new DJLEmbeddingService("data/models/all-MiniLM-L6-v2");
EmbeddingService cached = new CachedEmbeddingService(base);

// Láº§n 1: TÃ­nh toÃ¡n (cháº­m)
float[] emb1 = cached.embed("test");  // ~20ms

// Láº§n 2: Láº¥y tá»« cache (nhanh)
float[] emb2 = cached.embed("test");  // ~0.01ms
```

---

## ğŸ“– API Reference

### DJLEmbeddingService

#### Constructor

```java
public DJLEmbeddingService(String modelPath) throws IOException
```

**Parameters:**

- `modelPath` - ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a model (pháº£i cÃ³ `model.onnx`, `tokenizer.json`, `config.json`)

**Throws:**

- `IOException` - Náº¿u model khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng load Ä‘Æ°á»£c

**Example:**

```java
EmbeddingService service = new DJLEmbeddingService(
    "data/models/all-MiniLM-L6-v2"
);
```

#### Methods

##### `embed(String text)`

Táº¡o embedding vector cho má»™t text.

```java
public float[] embed(String text)
```

**Parameters:**

- `text` - Text cáº§n embed (tá»‘i Ä‘a 512 tokens)

**Returns:**

- `float[]` - Vector embedding Ä‘Ã£ Ä‘Æ°á»£c normalize (L2 norm = 1)

**Throws:**

- `RuntimeException` - Náº¿u inference failed

**Time complexity:** O(n) vá»›i n lÃ  sá»‘ tokens

**Example:**

```java
float[] vector = service.embed("Hello world");
```

##### `embedBatch(String[] texts)`

Táº¡o embeddings cho nhiá»u texts.

```java
public float[][] embedBatch(String[] texts)
```

**Parameters:**

- `texts` - Array of texts

**Returns:**

- `float[][]` - Array of embedding vectors

**Example:**

```java
float[][] vectors = service.embedBatch(new String[]{
    "Text 1",
    "Text 2",
    "Text 3"
});
```

##### `getDimension()`

Láº¥y sá»‘ chiá»u cá»§a embedding vector.

```java
public int getDimension()
```

**Returns:**

- `int` - Dimension (384 cho all-MiniLM-L6-v2)

##### `getModelName()`

Láº¥y tÃªn model.

```java
public String getModelName()
```

**Returns:**

- `String` - Model name

##### `close()`

Giáº£i phÃ³ng resources.

```java
public void close()
```

**Example:**

```java
try (DJLEmbeddingService service = new DJLEmbeddingService("...")) {
    // Use service
} // Auto-closes
```

#### Static Methods

##### `createDefault()`

Táº¡o service vá»›i model máº·c Ä‘á»‹nh.

```java
public static DJLEmbeddingService createDefault() throws IOException
```

**Returns:**

- `DJLEmbeddingService` - Service vá»›i model all-MiniLM-L6-v2

**Example:**

```java
EmbeddingService service = DJLEmbeddingService.createDefault();
```

---

## ğŸ”§ Troubleshooting

### Lá»—i: "Model not found"

**NguyÃªn nhÃ¢n:** Model chÆ°a Ä‘Æ°á»£c download

**Giáº£i phÃ¡p:**

```bash
./scripts/setup-embeddings-djl.sh
```

### Lá»—i: "zip END header not found"

**NguyÃªn nhÃ¢n:** JAR file bá»‹ corrupt

**Giáº£i phÃ¡p:**

```bash
# XÃ³a file bá»‹ lá»—i
rm lib/rag/*.jar

# Download láº¡i
./scripts/setup-embeddings-djl.sh
```

### Lá»—i: "OutOfMemoryError"

**NguyÃªn nhÃ¢n:** KhÃ´ng Ä‘á»§ heap memory

**Giáº£i phÃ¡p:**

```bash
# TÄƒng heap size khi cháº¡y
export JAVA_OPTS="-Xmx4g"
./scripts/run.sh
```

### Lá»—i: "UnsatisfiedLinkError" (Windows)

**NguyÃªn nhÃ¢n:** Thiáº¿u Visual C++ Redistributable

**Giáº£i phÃ¡p:**

1. Download [VC++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist)
2. CÃ i Ä‘áº·t
3. Restart application

### Performance cháº­m

**Giáº£i phÃ¡p:**

1. **Batch processing**: Embed nhiá»u texts cÃ¹ng lÃºc
2. **Caching**: Cache embeddings Ä‘Ã£ tÃ­nh
3. **Warm-up**: Cháº¡y vÃ i inference Ä‘á»ƒ JVM optimize
4. **Thread pool**: DÃ¹ng parallel processing

```java
// Warm-up
for (int i = 0; i < 10; i++) {
    service.embed("warmup");
}

// Parallel processing
List<String> texts = ...;
List<float[]> embeddings = texts.parallelStream()
    .map(service::embed)
    .collect(Collectors.toList());
```

---

## ğŸ“š TÃ i nguyÃªn

### Documentation

- **DJL Official**: https://djl.ai/
- **ONNX Runtime**: https://onnxruntime.ai/
- **Sentence Transformers**: https://www.sbert.net/

### Models

- **HuggingFace Models**: https://huggingface.co/sentence-transformers
- **Model Selection Guide**: `MODEL_SELECTION_GUIDE.md`
- **Model Comparison**: `MODEL_COMPARISON.md`

### Examples

- **Basic Example**: `src/main/java/com/noteflix/pcm/rag/examples/DJLEmbeddingExample.java`
- **RAG Example**: `src/main/java/com/noteflix/pcm/rag/examples/RAGExample.java`

### Community

- **DJL Discord**: https://discord.gg/deepjavalibrary
- **GitHub Issues**: https://github.com/deepjavalibrary/djl/issues

---

## ğŸ“ Best Practices

### 1. Resource Management

```java
// âœ… Good: Auto-close
try (DJLEmbeddingService service = new DJLEmbeddingService("...")) {
    float[] emb = service.embed("text");
}

// âŒ Bad: Memory leak
DJLEmbeddingService service = new DJLEmbeddingService("...");
service.embed("text");
// Never closed!
```

### 2. Reuse Service Instance

```java
// âœ… Good: Reuse
DJLEmbeddingService service = new DJLEmbeddingService("...");
for (String text : texts) {
    float[] emb = service.embed(text);
}
service.close();

// âŒ Bad: Recreate every time (slow!)
for (String text : texts) {
    DJLEmbeddingService service = new DJLEmbeddingService("...");
    float[] emb = service.embed(text);
    service.close();
}
```

### 3. Batch Processing

```java
// âœ… Good: Batch
float[][] embeddings = service.embedBatch(texts);

// âŒ Bad: One by one
float[][] embeddings = new float[texts.length][];
for (int i = 0; i < texts.length; i++) {
    embeddings[i] = service.embed(texts[i]);
}
```

### 4. Error Handling

```java
try {
    float[] emb = service.embed(text);
} catch (RuntimeException e) {
    log.error("Embedding failed for text: {}", text, e);
    // Fallback hoáº·c retry
}
```

---

## ğŸ“Š Performance Tips

### Benchmarks

| Operation            | Time   | Memory  |
|----------------------|--------|---------|
| Load model           | ~500ms | ~300 MB |
| First inference      | ~100ms | +50 MB  |
| Subsequent inference | ~20ms  | Stable  |
| Batch (10 texts)     | ~80ms  | Stable  |

### Optimization

1. **Warm-up JVM**: 10-20 inference calls
2. **Use caching**: Cache frequent queries
3. **Batch processing**: Process multiple texts together
4. **Thread pooling**: Parallel processing cho large datasets
5. **Model selection**: Chá»n model phÃ¹ há»£p (xem `MODEL_SELECTION_GUIDE.md`)

---

## ğŸ“ Changelog

### Version 2.1.0 (2025-11-14)

- âœ… Updated to ONNX Runtime 1.23.2 (latest stable version)
- âœ… Enhanced security with official Microsoft build
- âœ… Smaller file size (72MB vs 89MB)

### Version 2.0.0 (2024-11-13)

- âœ… Full DJL ONNX Runtime implementation
- âœ… Updated to DJL 0.35.0
- âœ… Updated to ONNX Runtime 1.19.0
- âœ… Improved error handling
- âœ… Better resource management

### Version 1.0.0 (Initial)

- âœ… Basic structure
- âŒ Placeholder implementation

---

## ğŸ¤ Contributing

Náº¿u báº¡n muá»‘n contribute:

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push vÃ  create Pull Request

---

## ğŸ“„ License

Xem `LICENSE` file trong root directory.

---

**Cáº­p nháº­t láº§n cuá»‘i:** 13/11/2024  
**PhiÃªn báº£n:** 2.0.0  
**TÃ¡c giáº£:** PCM Team


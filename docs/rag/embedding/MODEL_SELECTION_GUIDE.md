# H∆∞·ªõng d·∫´n Ch·ªçn Model Embedding

## üìö M·ª•c l·ª•c
- [Gi·ªõi thi·ªáu](#gi·ªõi-thi·ªáu)
- [Ma tr·∫≠n L·ª±a ch·ªçn](#ma-tr·∫≠n-l·ª±a-ch·ªçn)
- [Models ph·ªï bi·∫øn](#models-ph·ªï-bi·∫øn)
- [Use Cases](#use-cases)
- [Decision Tree](#decision-tree)
- [Setup Guide](#setup-guide)

---

## üéØ Gi·ªõi thi·ªáu

Vi·ªác ch·ªçn model embedding ph√π h·ª£p ph·ª• thu·ªôc v√†o nhi·ªÅu y·∫øu t·ªë:

### C√°c y·∫øu t·ªë c·∫ßn xem x√©t

| Y·∫øu t·ªë | C√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi |
|--------|---------------------|
| **Performance** | T·ªëc ƒë·ªô inference quan tr·ªçng nh∆∞ th·∫ø n√†o? |
| **Quality** | C·∫ßn ƒë·ªô ch√≠nh x√°c cao ƒë·∫øn m·ª©c n√†o? |
| **Memory** | C√≥ gi·ªõi h·∫°n v·ªÅ RAM kh√¥ng? |
| **Domain** | Domain/ng√¥n ng·ªØ chuy√™n bi·ªát kh√¥ng? |
| **Size** | C√≥ gi·ªõi h·∫°n v·ªÅ k√≠ch th∆∞·ªõc deployment? |
| **Multilingual** | C·∫ßn h·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ kh√¥ng? |

### Trade-offs ch√≠nh

```
Quality ‚Üê‚Üí Speed
Quality ‚Üê‚Üí Size
Quality ‚Üê‚Üí Memory
```

**Quy t·∫Øc chung:**
- Model l·ªõn h∆°n ‚Üí Ch·∫•t l∆∞·ª£ng t·ªët h∆°n, ch·∫≠m h∆°n
- Model nh·ªè h∆°n ‚Üí Nhanh h∆°n, ch·∫•t l∆∞·ª£ng th·∫•p h∆°n
- Multilingual models ‚Üí Ch·∫≠m h∆°n, c·∫ßn nhi·ªÅu memory h∆°n

---

## üìä Ma tr·∫≠n L·ª±a ch·ªçn

### Theo Use Case

| Use Case | Model khuy·∫øn ngh·ªã | L√Ω do |
|----------|-------------------|-------|
| **Code search/RAG** | all-MiniLM-L6-v2 | ‚úÖ C√¢n b·∫±ng speed/quality<br>‚úÖ K√≠ch th∆∞·ªõc nh·ªè<br>‚úÖ Nhanh |
| **Semantic search (General)** | all-mpnet-base-v2 | ‚úÖ Quality t·ªët nh·∫•t<br>‚ö†Ô∏è Ch·∫≠m h∆°n 1.5x |
| **Multilingual** | paraphrase-multilingual-mpnet-base-v2 | ‚úÖ H·ªó tr·ª£ 50+ ng√¥n ng·ªØ<br>‚ö†Ô∏è C·∫ßn nhi·ªÅu memory |
| **Real-time chat** | all-MiniLM-L6-v2 | ‚úÖ Inference < 20ms<br>‚úÖ Lightweight |
| **High accuracy** | all-mpnet-base-v2 | ‚úÖ State-of-the-art quality |
| **Large datasets** | all-MiniLM-L6-v2 | ‚úÖ Fast batch processing<br>‚úÖ Low memory |
| **Specialized (Legal, Medical)** | Legal-BERT, BioBERT | ‚úÖ Domain-specific |

### Theo Constraints

#### ∆Øu ti√™n T·ªëc ƒë·ªô

```
1. all-MiniLM-L6-v2       (~15-20ms)  ‚≠ê Khuy·∫øn ngh·ªã
2. all-MiniLM-L12-v2      (~25-30ms)
3. paraphrase-MiniLM-L6-v2 (~20ms)
```

#### ∆Øu ti√™n Ch·∫•t l∆∞·ª£ng

```
1. all-mpnet-base-v2      (Best)      ‚≠ê Khuy·∫øn ngh·ªã
2. all-roberta-large-v1   (Excellent, slow)
3. all-MiniLM-L12-v2      (Good)
```

#### ∆Øu ti√™n Memory

```
1. all-MiniLM-L6-v2       (~100 MB)   ‚≠ê Khuy·∫øn ngh·ªã
2. all-MiniLM-L12-v2      (~150 MB)
3. all-mpnet-base-v2      (~400 MB)
```

#### Multilingual

```
1. paraphrase-multilingual-mpnet-base-v2  (50+ langs) ‚≠ê Khuy·∫øn ngh·ªã
2. paraphrase-multilingual-MiniLM-L12-v2  (Faster)
3. distiluse-base-multilingual-cased-v2   (Smaller)
```

---

## üîç Models ph·ªï bi·∫øn

### 1. all-MiniLM-L6-v2 ‚≠ê **KHUY·∫æN NGH·ªä M·∫∂C ƒê·ªäNH**

**T·ªïng quan:**
- Model nh·ªè, nhanh, ch·∫•t l∆∞·ª£ng t·ªët
- "Sweet spot" cho h·∫ßu h·∫øt use cases

**Th√¥ng s·ªë:**
```yaml
Dimension: 384
Parameters: 22M
Model size: ~90 MB
Inference: ~15-20ms
Quality score: 69.4/100
```

**∆Øu ƒëi·ªÉm:**
- ‚úÖ C·ª±c k·ª≥ nhanh
- ‚úÖ K√≠ch th∆∞·ªõc nh·ªè
- ‚úÖ Ch·∫•t l∆∞·ª£ng t·ªët cho general use cases
- ‚úÖ Production-ready
- ‚úÖ √çt t·ªën memory

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ö†Ô∏è Quality kh√¥ng b·∫±ng MPNet
- ‚ö†Ô∏è Ch·ªâ ti·∫øng Anh

**Khi n√†o d√πng:**
- ‚úÖ Code search & RAG systems
- ‚úÖ Real-time applications
- ‚úÖ Large-scale deployments
- ‚úÖ Resource-constrained environments
- ‚úÖ Fast prototyping

**Setup:**
```bash
./scripts/setup-embeddings-djl.sh all-MiniLM-L6-v2
```

**Code:**
```java
EmbeddingService service = new DJLEmbeddingService(
    "data/models/all-MiniLM-L6-v2"
);
```

---

### 2. all-mpnet-base-v2 ‚≠ê **CH·∫§T L∆Ø·ª¢NG CAO NH·∫§T**

**T·ªïng quan:**
- Model ch·∫•t l∆∞·ª£ng cao nh·∫•t cho ti·∫øng Anh
- D·ª±a tr√™n MPNet architecture

**Th√¥ng s·ªë:**
```yaml
Dimension: 768
Parameters: 110M
Model size: ~420 MB
Inference: ~30-40ms
Quality score: 72.8/100 (Highest!)
```

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t
- ‚úÖ State-of-the-art performance
- ‚úÖ T·ªët cho semantic understanding
- ‚úÖ Robust v·ªõi diverse queries

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ö†Ô∏è Ch·∫≠m h∆°n 2x so v·ªõi MiniLM
- ‚ö†Ô∏è C·∫ßn nhi·ªÅu memory h∆°n
- ‚ö†Ô∏è Model size l·ªõn (~420 MB)

**Khi n√†o d√πng:**
- ‚úÖ High-accuracy applications
- ‚úÖ Semantic search (kh√¥ng realtime)
- ‚úÖ Quality > Speed
- ‚úÖ Sufficient resources

**Kh√¥ng d√πng khi:**
- ‚ùå Real-time requirements
- ‚ùå Resource constraints
- ‚ùå Mobile/edge deployment

**Setup:**
```bash
./scripts/setup-embeddings-djl.sh all-mpnet-base-v2
```

**Code:**
```java
EmbeddingService service = new DJLEmbeddingService(
    "data/models/all-mpnet-base-v2"
);
```

---

### 3. paraphrase-multilingual-mpnet-base-v2 ‚≠ê **CHO ƒêA NG√îN NG·ªÆ**

**T·ªïng quan:**
- H·ªó tr·ª£ 50+ ng√¥n ng·ªØ
- Cross-lingual semantic search

**Th√¥ng s·ªë:**
```yaml
Dimension: 768
Parameters: 278M
Model size: ~1 GB
Inference: ~50ms
Languages: 50+
Quality score: 65.7/100
```

**Ng√¥n ng·ªØ h·ªó tr·ª£:**
```
‚úÖ English, Ti·∫øng Vi·ªát, Chinese, Japanese, Korean
‚úÖ French, German, Spanish, Italian, Portuguese
‚úÖ Arabic, Hindi, Russian, Turkish, Thai
... v√† 35+ ng√¥n ng·ªØ kh√°c
```

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Multilingual support
- ‚úÖ Cross-lingual search
- ‚úÖ Unified embedding space
- ‚úÖ Good quality across languages

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ö†Ô∏è R·∫•t ch·∫≠m
- ‚ö†Ô∏è C·∫ßn nhi·ªÅu memory (~1.5 GB RAM)
- ‚ö†Ô∏è Model size l·ªõn
- ‚ö†Ô∏è Quality th·∫•p h∆°n monolingual

**Khi n√†o d√πng:**
- ‚úÖ Multilingual applications
- ‚úÖ Cross-language search
- ‚úÖ International products
- ‚úÖ Mixed-language content

**Setup:**
```bash
./scripts/setup-embeddings-djl.sh paraphrase-multilingual-mpnet-base-v2
```

---

### 4. all-MiniLM-L12-v2

**T·ªïng quan:**
- Version l·ªõn h∆°n c·ªßa MiniLM-L6
- Middle ground gi·ªØa speed v√† quality

**Th√¥ng s·ªë:**
```yaml
Dimension: 384
Parameters: 33M
Model size: ~120 MB
Inference: ~25ms
Quality score: 70.2/100
```

**So s√°nh v·ªõi L6:**
- Quality: +1% better
- Speed: 25% slower
- Size: 30% larger

**Khi n√†o d√πng:**
- ‚úÖ C·∫ßn quality t·ªët h∆°n L6 m·ªôt ch√∫t
- ‚úÖ V·∫´n gi·ªØ ƒë∆∞·ª£c t·ªëc ƒë·ªô t·ªët
- ‚úÖ C√≥ resources ƒë·ªß

**Kh√¥ng c·∫ßn d√πng n·∫øu:**
- ‚ùå L6 ƒë√£ ƒë·ªß t·ªët (h·∫ßu h·∫øt cases)
- ‚ùå C·∫ßn optimize memory

---

### 5. all-distilroberta-v1

**T·ªïng quan:**
- Distilled version c·ªßa RoBERTa
- C√¢n b·∫±ng gi·ªØa RoBERTa-large v√† MiniLM

**Th√¥ng s·ªë:**
```yaml
Dimension: 768
Parameters: 82M
Model size: ~330 MB
Inference: ~35ms
Quality score: 71.5/100
```

**Khi n√†o d√πng:**
- ‚úÖ C·∫ßn quality gi·ªØa MiniLM v√† MPNet
- ‚úÖ Code understanding t·ªët
- ‚úÖ Technical content

---

## üéØ Use Cases Chi ti·∫øt

### Use Case 1: Code Search & Documentation RAG

**Y√™u c·∫ßu:**
- Fast retrieval (< 50ms)
- Good semantic understanding
- Code + natural language
- Large codebase (1000s files)

**Model khuy·∫øn ngh·ªã:** `all-MiniLM-L6-v2`

**L√Ω do:**
```
‚úÖ Speed: ~15ms inference
‚úÖ Quality: ƒê·ªß t·ªët cho code search
‚úÖ Memory: C√≥ th·ªÉ cache nhi·ªÅu embeddings
‚úÖ Production-proven
```

**Alternative:** `all-MiniLM-L12-v2` (n·∫øu c·∫ßn quality t·ªët h∆°n)

---

### Use Case 2: Customer Support Chatbot

**Y√™u c·∫ßu:**
- Real-time response
- Semantic matching v·ªõi FAQ
- ~1000 FAQ entries
- Multilingual (optional)

**Model khuy·∫øn ngh·ªã:**

**Monolingual (English/Vietnamese):** `all-MiniLM-L6-v2`
```
‚úÖ Real-time: < 20ms
‚úÖ User experience: Instant
‚úÖ Cache: C√≥ th·ªÉ cache t·∫•t c·∫£ FAQ
```

**Multilingual:** `paraphrase-multilingual-MiniLM-L12-v2`
```
‚úÖ 50+ languages
‚ö†Ô∏è Slower (~40ms) - v·∫´n acceptable
```

---

### Use Case 3: Academic Paper Search

**Y√™u c·∫ßu:**
- High accuracy
- Scientific/technical content
- Complex queries
- Batch processing (offline)

**Model khuy·∫øn ngh·ªã:** `all-mpnet-base-v2`

**L√Ω do:**
```
‚úÖ Best quality: 72.8/100
‚úÖ Scientific understanding
‚úÖ Batch processing: Speed kh√¥ng quan tr·ªçng
‚úÖ Worth the trade-off
```

---

### Use Case 4: E-commerce Product Search

**Y√™u c·∫ßu:**
- Fast search (< 100ms total)
- Product descriptions
- User queries
- 10,000+ products

**Model khuy·∫øn ngh·ªã:** `all-MiniLM-L6-v2` + caching

**Strategy:**
```java
// Pre-compute t·∫•t c·∫£ product embeddings
float[][] productEmbeddings = precomputeEmbeddings(products);

// Runtime: Ch·ªâ embed user query
float[] queryEmb = service.embed(userQuery);

// Search: Vector similarity (c·ª±c nhanh)
List<Product> results = searchSimilar(queryEmb, productEmbeddings);
```

**Performance:**
- Pre-compute: 1 l·∫ßn (offline)
- Query embed: ~15ms
- Vector search: ~5ms
- **Total: ~20ms** ‚úÖ

---

### Use Case 5: Legal Document Analysis

**Y√™u c·∫ßu:**
- Legal domain
- High accuracy
- Complex legal language
- Batch processing

**Model khuy·∫øn ngh·ªã:** Domain-specific model

**Options:**
1. **Legal-BERT** (specialized)
2. **all-mpnet-base-v2** (general but good)
3. Fine-tune MiniLM tr√™n legal corpus

**Setup Legal-BERT:**
```bash
# Download t·ª´ HuggingFace
./scripts/setup-embeddings-djl.sh nlpaueb/legal-bert-base-uncased
```

---

## üå≥ Decision Tree

```
B·∫Øt ƒë·∫ßu
   ‚îÇ
   ‚îú‚îÄ C·∫ßn multilingual?
   ‚îÇ  ‚îú‚îÄ Yes ‚Üí paraphrase-multilingual-mpnet-base-v2
   ‚îÇ  ‚îî‚îÄ No ‚Üì
   ‚îÇ
   ‚îú‚îÄ ∆Øu ti√™n g√¨?
   ‚îÇ  ‚îú‚îÄ Quality > All
   ‚îÇ  ‚îÇ  ‚îî‚îÄ all-mpnet-base-v2 ‚≠ê
   ‚îÇ  ‚îÇ
   ‚îÇ  ‚îú‚îÄ Speed > All
   ‚îÇ  ‚îÇ  ‚îî‚îÄ all-MiniLM-L6-v2 ‚≠ê
   ‚îÇ  ‚îÇ
   ‚îÇ  ‚îî‚îÄ C√¢n b·∫±ng
   ‚îÇ     ‚îú‚îÄ General use ‚Üí all-MiniLM-L6-v2 ‚≠ê
   ‚îÇ     ‚îî‚îÄ Need better quality ‚Üí all-MiniLM-L12-v2
   ‚îÇ
   ‚îî‚îÄ Domain ƒë·∫∑c bi·ªát?
      ‚îú‚îÄ Code ‚Üí all-MiniLM-L6-v2
      ‚îú‚îÄ Legal ‚Üí Legal-BERT
      ‚îú‚îÄ Medical ‚Üí BioBERT
      ‚îî‚îÄ Scientific ‚Üí SciBERT ho·∫∑c all-mpnet-base-v2
```

---

## üöÄ Setup Guide

### Quick Setup

```bash
# 1. Ch·ªçn model
MODEL="all-MiniLM-L6-v2"  # ho·∫∑c model kh√°c

# 2. Download
./scripts/setup-embeddings-djl.sh $MODEL

# 3. Build
./scripts/build.sh

# 4. Test
java -cp "out:lib/javafx/*:lib/others/*:lib/rag/*" \
  com.noteflix.pcm.rag.examples.embedding.DJLEmbeddingExample
```

### Multiple Models

```bash
# Download nhi·ªÅu models
./scripts/setup-embeddings-djl.sh all-MiniLM-L6-v2
./scripts/setup-embeddings-djl.sh all-mpnet-base-v2
./scripts/setup-embeddings-djl.sh paraphrase-multilingual-mpnet-base-v2

# C·∫•u tr√∫c th∆∞ m·ª•c
data/models/
‚îú‚îÄ‚îÄ all-MiniLM-L6-v2/
‚îÇ   ‚îú‚îÄ‚îÄ model.onnx
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ all-mpnet-base-v2/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ paraphrase-multilingual-mpnet-base-v2/
    ‚îî‚îÄ‚îÄ ...
```

### Switching Models

```java
// Configuration
public class EmbeddingConfig {
    // Development: Fast
    public static final String DEV_MODEL = "all-MiniLM-L6-v2";
    
    // Production: Quality
    public static final String PROD_MODEL = "all-mpnet-base-v2";
}

// Usage
String model = isProduction() 
    ? EmbeddingConfig.PROD_MODEL 
    : EmbeddingConfig.DEV_MODEL;
    
EmbeddingService service = new DJLEmbeddingService(
    "data/models/" + model
);
```

---

## üìä Performance Comparison

### Inference Time (Single text)

```
all-MiniLM-L6-v2:              ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 15ms  ‚≠ê Nhanh nh·∫•t
all-MiniLM-L12-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 25ms
all-distilroberta-v1:          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 35ms
all-mpnet-base-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 40ms
multilingual-mpnet-base-v2:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 60ms
```

### Quality (MTEB Score)

```
all-mpnet-base-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 72.8  ‚≠ê T·ªët nh·∫•t
all-distilroberta-v1:          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 71.5
all-MiniLM-L12-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 70.2
all-MiniLM-L6-v2:              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 69.4
multilingual-mpnet-base-v2:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 65.7
```

### Memory Usage (Runtime)

```
all-MiniLM-L6-v2:              ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 100 MB  ‚≠ê Nh·ªè nh·∫•t
all-MiniLM-L12-v2:             ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 150 MB
all-distilroberta-v1:          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 300 MB
all-mpnet-base-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 400 MB
multilingual-mpnet-base-v2:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 800 MB
```

### Model Size (Disk)

```
all-MiniLM-L6-v2:              ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  90 MB
all-MiniLM-L12-v2:             ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 120 MB
all-distilroberta-v1:          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 330 MB
all-mpnet-base-v2:             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 420 MB
multilingual-mpnet-base-v2:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 1.0 GB
```

---

## üéØ Khuy·∫øn ngh·ªã t·ªïng h·ª£p

### Default Choice (90% cases)

```
Model: all-MiniLM-L6-v2
L√Ω do: Best balance speed/quality/size
```

### High-Quality Applications

```
Model: all-mpnet-base-v2
L√Ω do: Best quality, acceptable speed
```

### Multilingual Applications

```
Model: paraphrase-multilingual-mpnet-base-v2
L√Ω do: Best multilingual support
```

### Mobile/Edge Deployment

```
Model: all-MiniLM-L6-v2
L√Ω do: Smallest, fastest
```

---

## üìö Resources

- **Model Hub**: https://huggingface.co/sentence-transformers
- **Benchmarks**: https://www.sbert.net/docs/pretrained_models.html
- **MTEB Leaderboard**: https://huggingface.co/spaces/mteb/leaderboard
- **Model Comparison**: `MODEL_COMPARISON.md`

---

**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi:** 13/11/2024  
**T√°c gi·∫£:** PCM Team


# So sÃ¡nh Models vÃ  Benchmarks

## ğŸ“š Má»¥c lá»¥c

- [Tá»•ng quan](#tá»•ng-quan)
- [Comparison Matrix](#comparison-matrix)
- [Detailed Benchmarks](#detailed-benchmarks)
- [Real-world Performance](#real-world-performance)
- [Use Case Recommendations](#use-case-recommendations)
- [Migration Guide](#migration-guide)

---

## ğŸ¯ Tá»•ng quan

Document nÃ y cung cáº¥p so sÃ¡nh chi tiáº¿t vá» performance, quality vÃ  resource usage cá»§a cÃ¡c embedding models phá»• biáº¿n.

### Testing Environment

```yaml
Hardware:
  CPU: Apple M2 (8-core)
  RAM: 16 GB
  Storage: SSD

Software:
  Java: OpenJDK 21
  DJL: 0.35.0
  ONNX Runtime: 1.23.2

Test Data:
  Sentences: 1000 diverse texts
  Lengths: 10-100 words
  Domains: code, docs, general
```

---

## ğŸ“Š Comparison Matrix

### Quick Comparison

| Model                    | Dim | Speed | Quality | Memory     | Size  | Multilingual |
|--------------------------|-----|-------|---------|------------|-------|--------------|
| **all-MiniLM-L6-v2**     | 384 | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­    | ğŸ’šğŸ’šğŸ’šğŸ’šğŸ’š | 90MB  | âŒ            |
| **all-MiniLM-L12-v2**    | 384 | âš¡âš¡âš¡âš¡  | â­â­â­â­    | ğŸ’šğŸ’šğŸ’šğŸ’š   | 120MB | âŒ            |
| **all-distilroberta-v1** | 768 | âš¡âš¡âš¡   | â­â­â­â­â­   | ğŸ’šğŸ’šğŸ’š     | 330MB | âŒ            |
| **all-mpnet-base-v2**    | 768 | âš¡âš¡âš¡   | â­â­â­â­â­   | ğŸ’šğŸ’šğŸ’š     | 420MB | âŒ            |
| **multilingual-mpnet**   | 768 | âš¡âš¡    | â­â­â­â­    | ğŸ’šğŸ’š       | 1GB   | âœ… 50+        |

### Detailed Specifications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MODEL SPECIFICATIONS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model               â”‚ Params â”‚ Dim      â”‚ Layers   â”‚ Hidden â”‚ Vocab    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MiniLM-L6-v2        â”‚ 22M    â”‚ 384      â”‚ 6        â”‚ 384    â”‚ 30K      â”‚
â”‚ MiniLM-L12-v2       â”‚ 33M    â”‚ 384      â”‚ 12       â”‚ 384    â”‚ 30K      â”‚
â”‚ distilroberta-v1    â”‚ 82M    â”‚ 768      â”‚ 6        â”‚ 768    â”‚ 50K      â”‚
â”‚ mpnet-base-v2       â”‚ 110M   â”‚ 768      â”‚ 12       â”‚ 768    â”‚ 30K      â”‚
â”‚ multilingual-mpnet  â”‚ 278M   â”‚ 768      â”‚ 12       â”‚ 768    â”‚ 250K     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Detailed Benchmarks

### 1. Inference Speed

#### Single Text Embedding

```
Test: Embed má»™t cÃ¢u vÄƒn (50 words)
Runs: 1000 iterations (warm JVM)
Measurement: Average time

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Avg (ms)   â”‚ Min (ms)     â”‚ Max (ms)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 15.2       â”‚ 12.3         â”‚ 18.7         â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 24.8       â”‚ 21.5         â”‚ 29.3         â”‚
â”‚ all-distilroberta-v1        â”‚ 34.6       â”‚ 31.2         â”‚ 41.8         â”‚
â”‚ all-mpnet-base-v2           â”‚ 39.4       â”‚ 35.8         â”‚ 46.2         â”‚
â”‚ multilingual-mpnet          â”‚ 58.7       â”‚ 54.3         â”‚ 67.9         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Winner: all-MiniLM-L6-v2 (2.6x faster than mpnet-base-v2)
```

#### Batch Processing

```
Test: Embed 100 texts cÃ¹ng lÃºc
Measurement: Total time / throughput

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Total (s)  â”‚ Per text (ms)â”‚ Throughput   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 1.2        â”‚ 12.0         â”‚ 83 texts/s   â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 2.0        â”‚ 20.0         â”‚ 50 texts/s   â”‚
â”‚ all-distilroberta-v1        â”‚ 3.1        â”‚ 31.0         â”‚ 32 texts/s   â”‚
â”‚ all-mpnet-base-v2           â”‚ 3.6        â”‚ 36.0         â”‚ 28 texts/s   â”‚
â”‚ multilingual-mpnet          â”‚ 5.4        â”‚ 54.0         â”‚ 19 texts/s   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Winner: all-MiniLM-L6-v2 (3x throughput vs mpnet-base-v2)
```

#### Cold Start (First Inference)

```
Test: Thá»i gian inference Ä‘áº§u tiÃªn (chÆ°a warm-up JVM)

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Load (ms)  â”‚ First inference (ms)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 342        â”‚ 124                    â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 398        â”‚ 156                    â”‚
â”‚ all-distilroberta-v1        â”‚ 612        â”‚ 243                    â”‚
â”‚ all-mpnet-base-v2           â”‚ 734        â”‚ 287                    â”‚
â”‚ multilingual-mpnet          â”‚ 1834       â”‚ 421                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: Sau ~10 inference calls, performance á»•n Ä‘á»‹nh
```

### 2. Quality Benchmarks

#### MTEB (Massive Text Embedding Benchmark)

```
Dataset: 56 diverse tasks
Measurement: Average score (0-100)

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Overall  â”‚ Retrieval  â”‚ Clustering â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-mpnet-base-v2           â”‚ 72.8 â­  â”‚ 74.2       â”‚ 68.5       â”‚
â”‚ all-distilroberta-v1        â”‚ 71.5     â”‚ 72.8       â”‚ 67.1       â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 70.2     â”‚ 71.5       â”‚ 65.8       â”‚
â”‚ all-MiniLM-L6-v2            â”‚ 69.4     â”‚ 70.8       â”‚ 64.3       â”‚
â”‚ multilingual-mpnet          â”‚ 65.7     â”‚ 67.2       â”‚ 61.5       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Winner: all-mpnet-base-v2 (Best quality)
Best value: all-MiniLM-L6-v2 (Quality/Speed ratio)
```

#### Semantic Textual Similarity (STS)

```
Dataset: STS Benchmark
Task: ÄÃ¡nh giÃ¡ similarity giá»¯a cÃ¡c cÃ¢u
Measurement: Spearman correlation (0-1, higher is better)

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ STS-B    â”‚ STS12    â”‚ STS16    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-mpnet-base-v2           â”‚ 0.863    â”‚ 0.778    â”‚ 0.824    â”‚
â”‚ all-distilroberta-v1        â”‚ 0.852    â”‚ 0.765    â”‚ 0.812    â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 0.844    â”‚ 0.758    â”‚ 0.805    â”‚
â”‚ all-MiniLM-L6-v2            â”‚ 0.836    â”‚ 0.751    â”‚ 0.798    â”‚
â”‚ multilingual-mpnet          â”‚ 0.801    â”‚ 0.712    â”‚ 0.765    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Insight: Quality gap < 4% giá»¯a MiniLM-L6 vÃ  MPNet
```

#### Code Search Quality

```
Dataset: Internal code corpus (1000 Java files)
Task: TÃ¬m relevant code snippets
Measurement: MRR@10 (Mean Reciprocal Rank)

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ MRR@10   â”‚ Hit@1    â”‚ Hit@5     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-mpnet-base-v2           â”‚ 0.742    â”‚ 0.621    â”‚ 0.834     â”‚
â”‚ all-distilroberta-v1        â”‚ 0.738    â”‚ 0.615    â”‚ 0.829     â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 0.729    â”‚ 0.608    â”‚ 0.821     â”‚
â”‚ all-MiniLM-L6-v2            â”‚ 0.724 â­ â”‚ 0.602    â”‚ 0.815     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Insight: Cho code search, MiniLM-L6 Ä‘á»§ tá»‘t (2.5% gap vs MPNet)
         nhÆ°ng nhanh hÆ¡n 2.6x
```

### 3. Memory Usage

#### Runtime Memory (Heap)

```
Test: Memory consumption during inference
Measurement: JVM heap usage

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Base    â”‚ Peak    â”‚ Stable   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 85 MB   â”‚ 145 MB  â”‚ 110 MB   â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 112 MB  â”‚ 185 MB  â”‚ 148 MB   â”‚
â”‚ all-distilroberta-v1        â”‚ 265 MB  â”‚ 380 MB  â”‚ 312 MB   â”‚
â”‚ all-mpnet-base-v2           â”‚ 352 MB  â”‚ 490 MB  â”‚ 418 MB   â”‚
â”‚ multilingual-mpnet          â”‚ 742 MB  â”‚ 1.2 GB  â”‚ 856 MB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Test conditions: 
- After 100 inference calls
- Single instance
- No caching
```

#### Model File Size

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ model.onnx   â”‚ tokenizer  â”‚ Total    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 85 MB        â”‚ 5 MB       â”‚ 90 MB    â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 115 MB       â”‚ 5 MB       â”‚ 120 MB   â”‚
â”‚ all-distilroberta-v1        â”‚ 322 MB       â”‚ 8 MB       â”‚ 330 MB   â”‚
â”‚ all-mpnet-base-v2           â”‚ 410 MB       â”‚ 8 MB       â”‚ 418 MB   â”‚
â”‚ multilingual-mpnet          â”‚ 985 MB       â”‚ 15 MB      â”‚ 1.0 GB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Embedding Storage

```
Scenario: Store embeddings for 100,000 documents

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Dimension  â”‚ Per doc    â”‚ Total    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 384        â”‚ 1.5 KB     â”‚ 150 MB   â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 384        â”‚ 1.5 KB     â”‚ 150 MB   â”‚
â”‚ all-distilroberta-v1        â”‚ 768        â”‚ 3.0 KB     â”‚ 300 MB   â”‚
â”‚ all-mpnet-base-v2           â”‚ 768        â”‚ 3.0 KB     â”‚ 300 MB   â”‚
â”‚ multilingual-mpnet          â”‚ 768        â”‚ 3.0 KB     â”‚ 300 MB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: float32 format, khÃ´ng nÃ©n
```

---

## ğŸŒ Real-world Performance

### Use Case 1: Code Documentation Search

**Setup:**

- 5,000 Java files
- Average file: 200 lines
- Queries: Natural language questions

**Results:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Index    â”‚ Query    â”‚ Quality  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2 â­         â”‚ 45s      â”‚ 18ms     â”‚ 89%      â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 68s      â”‚ 28ms     â”‚ 90%      â”‚
â”‚ all-mpnet-base-v2           â”‚ 112s     â”‚ 43ms     â”‚ 92%      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recommendation: all-MiniLM-L6-v2
Reason: 
  - Query speed: User-facing, critical
  - Quality: 89% Ä‘á»§ tá»‘t
  - Index time: 45s acceptable (one-time)
  - Memory: Can handle large codebases
```

### Use Case 2: Customer Support FAQ

**Setup:**

- 2,000 FAQ entries
- ~1,000 queries/day
- Real-time requirement: < 100ms

**Results:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Load     â”‚ Query    â”‚ P95      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2 â­         â”‚ 342ms    â”‚ 15ms     â”‚ 23ms     â”‚
â”‚ multilingual-mpnet          â”‚ 1834ms   â”‚ 58ms     â”‚ 89ms     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recommendation: 
  - English only: all-MiniLM-L6-v2
  - Multilingual: multilingual-mpnet (cáº§n optimize)
```

### Use Case 3: Academic Paper Search

**Setup:**

- 100,000 papers
- Complex scientific queries
- Batch processing (offline)

**Results:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Index    â”‚ Search   â”‚ NDCG@10  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-mpnet-base-v2 â­        â”‚ 15min    â”‚ 45ms     â”‚ 0.842    â”‚
â”‚ all-MiniLM-L6-v2            â”‚ 8min     â”‚ 18ms     â”‚ 0.813    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recommendation: all-mpnet-base-v2
Reason:
  - Quality: Critical (academic precision)
  - Speed: Not critical (batch processing)
  - Index time: One-time cost, acceptable
```

### Use Case 4: E-commerce Product Search

**Setup:**

- 50,000 products
- User search queries
- Target: < 50ms response

**Strategy: Pre-compute + Runtime**

```
Phase 1: Pre-compute (offline)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ all-MiniLM-L6-v2            â”‚ 8 minutes                â”‚
â”‚ all-mpnet-base-v2           â”‚ 14 minutes               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 2: Runtime search
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Embed Q  â”‚ Vector Searchâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2 â­         â”‚ 15ms     â”‚ 3ms          â”‚
â”‚ all-mpnet-base-v2           â”‚ 39ms     â”‚ 3ms          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total response time:
  - MiniLM: ~18ms âœ… (under 50ms target)
  - MPNet: ~42ms âœ… (under 50ms, but slower)

Recommendation: all-MiniLM-L6-v2
```

---

## ğŸ¯ Use Case Recommendations

### Matrix Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use Case                   â”‚ Recommended Model                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Code Search                â”‚ all-MiniLM-L6-v2 â­                      â”‚
â”‚ Documentation RAG          â”‚ all-MiniLM-L6-v2 â­                      â”‚
â”‚ Chatbot/FAQ                â”‚ all-MiniLM-L6-v2 â­                      â”‚
â”‚ Real-time Search           â”‚ all-MiniLM-L6-v2 â­                      â”‚
â”‚ Large-scale (1M+ docs)     â”‚ all-MiniLM-L6-v2 â­                      â”‚
â”‚                            â”‚                                          â”‚
â”‚ Academic Search            â”‚ all-mpnet-base-v2 â­                     â”‚
â”‚ High-accuracy Required     â”‚ all-mpnet-base-v2 â­                     â”‚
â”‚ Small datasets (<10K)      â”‚ all-mpnet-base-v2 â­                     â”‚
â”‚ Quality > Speed            â”‚ all-mpnet-base-v2 â­                     â”‚
â”‚                            â”‚                                          â”‚
â”‚ Multilingual               â”‚ paraphrase-multilingual-mpnet-base-v2 â­ â”‚
â”‚ International Products     â”‚ paraphrase-multilingual-mpnet-base-v2 â­ â”‚
â”‚ Cross-language Search      â”‚ paraphrase-multilingual-mpnet-base-v2 â­ â”‚
â”‚                            â”‚                                          â”‚
â”‚ Balance Quality/Speed      â”‚ all-MiniLM-L12-v2 â­                     â”‚
â”‚ Upgrade from L6            â”‚ all-MiniLM-L12-v2 â­                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 90-10 Rule

**90% of use cases:** `all-MiniLM-L6-v2`

- Fast enough
- Quality good enough
- Resource efficient

**10% of use cases requiring:**

- **Best quality:** `all-mpnet-base-v2`
- **Multilingual:** `paraphrase-multilingual-mpnet-base-v2`
- **Domain-specific:** Specialized models

---

## ğŸ”„ Migration Guide

### From MiniLM-L6 to MPNet

**Khi nÃ o migrate:**

- Quality khÃ´ng Ä‘á»§ tá»‘t
- CÃ³ thÃªm resources
- Speed khÃ´ng pháº£i váº¥n Ä‘á»

**Impact:**

```
Quality:    +4.9%  (69.4 â†’ 72.8)
Speed:      -61%   (15ms â†’ 39ms)
Memory:     +280%  (110MB â†’ 418MB)
Model size: +364%  (90MB â†’ 418MB)
```

**Migration steps:**

```bash
# 1. Download new model
./scripts/setup-embeddings-djl.sh all-mpnet-base-v2

# 2. Update configuration
# Before:
EmbeddingService service = new DJLEmbeddingService(
    "data/models/all-MiniLM-L6-v2"
);

# After:
EmbeddingService service = new DJLEmbeddingService(
    "data/models/all-mpnet-base-v2"
);

# 3. Re-index all documents (IMPORTANT!)
# Embeddings are not compatible between models
```

**âš ï¸ Important:**

- Embeddings tá»« models khÃ¡c nhau KHÃ”NG tÆ°Æ¡ng thÃ­ch
- Pháº£i re-index toÃ n bá»™ documents
- Dimension khÃ¡c nhau: 384 â†’ 768

### From Monolingual to Multilingual

**Impact:**

```
Languages:  English â†’ 50+ languages
Speed:      -74%    (15ms â†’ 58ms)
Memory:     +678%   (110MB â†’ 856MB)
Quality:    -5.3%   (69.4 â†’ 65.7, English only)
```

**When to migrate:**

- Need multilingual support
- Worth the performance trade-off

**Code:**

```java
// Same interface, just change model path
EmbeddingService service = new DJLEmbeddingService(
    "data/models/paraphrase-multilingual-mpnet-base-v2"
);

// Now supports multiple languages
float[] en = service.embed("Hello world");
float[] vi = service.embed("Xin chÃ o tháº¿ giá»›i");
float[] zh = service.embed("ä½ å¥½ä¸–ç•Œ");

// Can compute cross-lingual similarity
float similarity = cosineSimilarity(en, vi);
```

---

## ğŸ“ˆ Performance Optimization Tips

### 1. Caching

```java
Map<String, float[]> cache = new ConcurrentHashMap<>();

public float[] embedWithCache(String text) {
    return cache.computeIfAbsent(text, service::embed);
}

// Performance improvement:
// - Cache hit: ~0.01ms (1500x faster!)
// - Cache miss: normal speed
```

### 2. Batch Processing

```java
// âŒ Bad: One by one
for (String text : texts) {
    embeddings.add(service.embed(text));
}
// Time: 1000 * 15ms = 15,000ms

// âœ… Good: Batch
float[][] embeddings = service.embedBatch(texts);
// Time: ~12,000ms (20% faster)
```

### 3. Parallel Processing

```java
List<float[]> embeddings = texts.parallelStream()
    .map(service::embed)
    .collect(Collectors.toList());

// Performance on multi-core:
// - Single-thread: 15,000ms
// - 4 cores: ~4,500ms (3.3x speedup)
// - 8 cores: ~2,800ms (5.4x speedup)
```

### 4. Pre-computation

```java
// Offline: Pre-compute document embeddings
float[][] docEmbeddings = precomputeDocuments(documents);
saveEmbeddings(docEmbeddings);

// Online: Only embed query
float[] queryEmb = service.embed(query);
List<Document> results = searchSimilar(queryEmb, docEmbeddings);

// Benefits:
// - Query time: 15ms (embed) + 3ms (search) = 18ms
// - No need to embed documents at runtime
```

---

## ğŸ† Winner by Category

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category                     â”‚ Winner                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸƒ Fastest                  â”‚ all-MiniLM-L6-v2 (15ms)             â”‚
â”‚ ğŸ† Best Quality             â”‚ all-mpnet-base-v2 (72.8)            â”‚
â”‚ ğŸ’š Most Efficient           â”‚ all-MiniLM-L6-v2 (110MB)            â”‚
â”‚ ğŸ“¦ Smallest Size            â”‚ all-MiniLM-L6-v2 (90MB)             â”‚
â”‚ âš–ï¸ Best Balance             â”‚ all-MiniLM-L6-v2                    â”‚
â”‚ ğŸŒ Best Multilingual        â”‚ multilingual-mpnet-base-v2          â”‚
â”‚ ğŸ’° Best Value               â”‚ all-MiniLM-L6-v2                    â”‚
â”‚ ğŸš€ Production Ready         â”‚ all-MiniLM-L6-v2                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Score Card

### Overall Ratings (0-10)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                        â”‚ Speed â”‚ Quality â”‚ Memory â”‚ Size â”‚ Overall â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ all-MiniLM-L6-v2            â”‚ 10    â”‚ 8.5     â”‚ 10     â”‚ 10   â”‚ 9.6 â­  â”‚
â”‚ all-MiniLM-L12-v2           â”‚ 8     â”‚ 9.0     â”‚ 9      â”‚ 9    â”‚ 8.8     â”‚
â”‚ all-distilroberta-v1        â”‚ 6     â”‚ 9.5     â”‚ 7      â”‚ 6    â”‚ 7.1     â”‚
â”‚ all-mpnet-base-v2           â”‚ 5     â”‚ 10      â”‚ 6      â”‚ 5    â”‚ 6.5     â”‚
â”‚ multilingual-mpnet          â”‚ 3     â”‚ 8.0     â”‚ 3      â”‚ 2    â”‚ 4.0     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Overall winner: all-MiniLM-L6-v2
```

---

## ğŸ“š Resources

- **MTEB Leaderboard**: https://huggingface.co/spaces/mteb/leaderboard
- **Sentence Transformers**: https://www.sbert.net/docs/pretrained_models.html
- **DJL Docs**: https://djl.ai/
- **Selection Guide**: `MODEL_SELECTION_GUIDE.md`
- **DJL Overview**: `DJL_OVERVIEW.md`

---

## ğŸ¯ Quick Decision

### Chá»n model trong 30 giÃ¢y:

**1. Báº¡n cáº§n multilingual?**

- Yes â†’ `paraphrase-multilingual-mpnet-base-v2`
- No â†’ Tiáº¿p ğŸ‘‡

**2. Resources cÃ³ giá»›i háº¡n? (RAM < 1GB hoáº·c cáº§n fast)**

- Yes â†’ `all-MiniLM-L6-v2` â­
- No â†’ Tiáº¿p ğŸ‘‡

**3. Quality quan trá»ng nháº¥t?**

- Yes â†’ `all-mpnet-base-v2`
- No â†’ `all-MiniLM-L6-v2` â­

**Default choice:** `all-MiniLM-L6-v2` âœ…

---

**Cáº­p nháº­t láº§n cuá»‘i:** 13/11/2024  
**TÃ¡c giáº£:** PCM Team  
**Tested on:** Apple M2, 16GB RAM, Java 21


# üîå Custom API Provider - H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng

> Provider cho LLM service ri√™ng c·ªßa b·∫°n v·ªõi 3 API endpoints

---

## üìã **T·ªïng Quan**

**CustomAPIProvider** l√† provider ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát cho service LLM ri√™ng c·ªßa b·∫°n v·ªõi:
- ‚úÖ Conversation management (t·∫°o & tracking conversation ID)
- ‚úÖ SSE streaming v·ªõi **thinking mode** built-in
- ‚úÖ Function calling (inject v√†o content)
- ‚úÖ Token tracking (remaining tokens API)

---

## üèóÔ∏è **API Endpoints**

### 1. **POST /api/chat/create**
T·∫°o conversation m·ªõi, tr·∫£ v·ªÅ ID.

**Request:**
```json
{
  // Empty or with metadata
}
```

**Response:**
```json
{
  "id": "conv_12345"
}
// ho·∫∑c
{
  "conversation_id": "conv_12345"
}
// ho·∫∑c tr·∫£ v·ªÅ tr·ª±c ti·∫øp string: "conv_12345"
```

### 2. **POST /api/chat/stream**
Stream chat v·ªõi LLM (SSE format).

**Request:**
```json
{
  "conversation_id": "conv_12345",
  "content": "User message here...",
  "model": "default"
}
```

**Response (SSE):**
```
data: {"type": "thinking", "content": "Let me think..."}

data: {"type": "token", "content": "The"}

data: {"type": "token", "content": " answer"}

data: {"type": "token", "content": " is"}

data: {"type": "done", "usage": {"prompt_tokens": 10, "completion_tokens": 20}}
```

### 3. **GET /api/chat/tokens/{conversationId}**
L·∫•y s·ªë token c√≤n l·∫°i c·ªßa conversation.

**Response:**
```json
{
  "remaining_tokens": 1500
}
// ho·∫∑c
{
  "tokens": 1500
}
// ho·∫∑c tr·∫£ v·ªÅ tr·ª±c ti·∫øp number: 1500
```

---

## üöÄ **C√°ch S·ª≠ D·ª•ng**

### 1. Setup Provider

```java
import com.noteflix.pcm.llm.provider.CustomAPIProvider;
import com.noteflix.pcm.llm.model.ProviderConfig;
import com.noteflix.pcm.llm.registry.ProviderRegistry;

// Create provider
CustomAPIProvider provider = new CustomAPIProvider();

// Configure
provider.configure(ProviderConfig.builder()
    .baseUrl("https://your-api.com")  // ‚¨ÖÔ∏è Base URL c·ªßa service
    .apiKey("your_api_key")           // ‚¨ÖÔ∏è API key (optional n·∫øu kh√¥ng c·∫ßn auth)
    .model("default")                 // ‚¨ÖÔ∏è Default model
    .timeoutMs(60000)                 // 60 seconds timeout
    .maxRetries(3)                    // Retry 3 l·∫ßn n·∫øu fail
    .build());

// Register
ProviderRegistry.getInstance().register("custom", provider);
ProviderRegistry.getInstance().setActive("custom");
```

### 2. Simple Chat

```java
List<Message> messages = List.of(
    Message.system("You are a helpful assistant."),
    Message.user("What is quantum computing?")
);

CompletableFuture<ChatResponse> future = provider.chat(messages, ChatOptions.defaults());
ChatResponse response = future.get();

System.out.println("Response: " + response.getContent());

// Check thinking (n·∫øu c√≥)
if (response.getThinkingContent() != null) {
    System.out.println("Thinking: " + response.getThinkingContent());
}

// Check usage
if (response.getUsage() != null) {
    System.out.println("Tokens: " + response.getTotalTokens());
}
```

### 3. Streaming v·ªõi Thinking

```java
provider.chatStream(messages, ChatOptions.defaults(), new ChatEventAdapter() {
    
    @Override
    public void onThinking(String thinking) {
        // Thinking mode - hi·ªán trong UI v·ªõi style kh√°c
        System.out.print("[Thinking] " + thinking);
    }
    
    @Override
    public void onToken(String token) {
        // Regular content - append v√†o text area
        System.out.print(token);
    }
    
    @Override
    public void onComplete(ChatResponse response) {
        System.out.println("\nDone!");
        if (response.getUsage() != null) {
            System.out.println("Total tokens: " + response.getTotalTokens());
        }
    }
    
    @Override
    public void onError(Throwable error) {
        System.err.println("Error: " + error.getMessage());
    }
});
```

### 4. Function Calling (Injected)

V√¨ API c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ function calling native, provider s·∫Ω **inject function definitions v√†o content**.

```java
FunctionRegistry funcRegistry = FunctionRegistry.getInstance();

// Register function (d√πng @LLMFunction annotation ho·∫∑c manual)
// ... (xem QUICK_START.md)

ChatOptions options = ChatOptions.withTools(funcRegistry.getAllTools());

ChatResponse response = provider.chat(messages, options).get();

// LLM s·∫Ω nh·∫≠n ƒë∆∞·ª£c content k√®m theo function definitions:
/*
[user]: What's the weather in Paris?

--- AVAILABLE FUNCTIONS ---
You can call these functions by responding in this format:
<function_call>
  <name>function_name</name>
  <arguments>{"arg1": "value1"}</arguments>
</function_call>

Available functions:
- get_weather: Get current weather for a location
  Parameters:
    - location (string): City name
*/

// Parse response ƒë·ªÉ detect function call
if (response.getContent().contains("<function_call>")) {
    // Parse XML v√† execute function
    // Sau ƒë√≥ g·ª≠i k·∫øt qu·∫£ l·∫°i cho LLM
}
```

### 5. Token Tracking

```java
// Chat first
ChatResponse response = provider.chat(messages, ChatOptions.defaults()).get();

// Get remaining tokens
String conversationId = response.getId();
int remainingTokens = provider.getRemainingTokens(conversationId);

System.out.println("Remaining tokens: " + remainingTokens);

// Alert user if low
if (remainingTokens < 100) {
    System.out.println("‚ö†Ô∏è Warning: Low tokens remaining!");
}
```

### 6. JavaFX UI Integration

```java
// In your ViewModel
public void sendMessage(String userMessage) {
    setBusy(true);
    
    List<Message> messages = buildConversation(userMessage);
    
    provider.chatStream(messages, ChatOptions.defaults(), new ChatEventAdapter() {
        
        @Override
        public void onThinking(String thinking) {
            Platform.runLater(() -> {
                thinkingLabel.setText(thinking);
                thinkingLabel.setVisible(true);
            });
        }
        
        @Override
        public void onToken(String token) {
            Platform.runLater(() -> {
                responseTextArea.appendText(token);
                scrollToBottom();
            });
        }
        
        @Override
        public void onComplete(ChatResponse response) {
            Platform.runLater(() -> {
                thinkingLabel.setVisible(false);
                setBusy(false);
                
                // Update token count
                tokensLabel.setText("Tokens: " + response.getTotalTokens());
                
                // Check remaining
                try {
                    int remaining = provider.getRemainingTokens(response.getId());
                    remainingLabel.setText("Remaining: " + remaining);
                } catch (Exception e) {
                    log.warn("Could not get remaining tokens", e);
                }
            });
        }
        
        @Override
        public void onError(Throwable error) {
            Platform.runLater(() -> {
                setBusy(false);
                showError(error.getMessage());
            });
        }
    });
}
```

---

## ‚öôÔ∏è **T√πy Ch·ªânh**

### Conversation Caching

Provider t·ª± ƒë·ªông cache conversation IDs ƒë·ªÉ t√°i s·ª≠ d·ª•ng:

```java
// Clear cache for specific key
provider.clearConversationCache("cache_key");

// Clear all cached conversations
provider.clearConversationCache(null);
```

### Custom SSE Response Format

N·∫øu SSE response format c·ªßa b·∫°n kh√°c, s·ª≠a trong method `streamChat()`:

```java
// Line 330-380 trong CustomAPIProvider.java
if (type.equals("your_thinking_type")) {
    // Handle thinking
} else if (type.equals("your_token_type")) {
    // Handle token
}
```

### Custom Create Conversation Format

N·∫øu create conversation API c·∫ßn metadata, s·ª≠a trong method `getOrCreateConversation()`:

```java
// Line 145 trong CustomAPIProvider.java
ObjectNode requestBody = objectMapper.createObjectNode();
requestBody.put("user_id", userId);
requestBody.put("metadata", metadata);
```

---

## üéØ **Features**

### ‚úÖ Conversation Management
- T·ª± ƒë·ªông t·∫°o conversation khi c·∫ßn
- Cache conversation IDs ƒë·ªÉ reuse
- Customizable cache strategy

### ‚úÖ Thinking Mode (Built-in!)
- T·ª± ƒë·ªông detect `"type": "thinking"` trong SSE
- Trigger `onThinking()` callback
- Hi·ªÉn th·ªã ri√™ng trong UI

### ‚úÖ Function Calling (Injected)
- Inject function definitions v√†o content
- Format: XML-style `<function_call>...</function_call>`
- LLM response theo format ƒë·ªÉ call functions
- B·∫°n parse v√† execute

### ‚úÖ Token Tracking
- Check remaining tokens cho conversation
- Alert user khi s·∫Øp h·∫øt tokens
- Monitor usage cho m·ªói request

### ‚úÖ Error Handling
- Retry logic v·ªõi exponential backoff
- Comprehensive error messages
- `onError()` callback cho UI

---

## üìù **V√≠ D·ª• ƒê·∫ßy ƒê·ªß**

Xem file: `src/main/java/com/noteflix/pcm/llm/examples/CustomAPIUsageExample.java`

4 examples:
1. Basic setup & chat
2. Streaming v·ªõi thinking
3. Function calling (injected)
4. Token tracking

---

## üîç **Troubleshooting**

### Provider not ready?
```java
if (!provider.isReady()) {
    throw new IllegalStateException("Provider not configured");
}

// Ho·∫∑c test connection
boolean connected = provider.testConnection();
```

### SSE format kh√¥ng match?
Ki·ªÉm tra logs ƒë·ªÉ xem format response:
```java
log.debug("SSE chunk: {}", data);
```

Sau ƒë√≥ s·ª≠a parsing logic trong `streamChat()` method.

### Function calling kh√¥ng work?
Check content ƒë∆∞·ª£c g·ª≠i l√™n API:
```java
String content = buildContentWithFunctions(messages, options);
log.info("Content with functions: {}", content);
```

### Conversation ID b·ªã conflict?
Clear cache:
```java
provider.clearConversationCache(null);
```

---

## üìä **Response Format Examples**

### Option 1: Structured JSON
```json
{
  "type": "thinking",
  "content": "Let me analyze this..."
}
```

### Option 2: OpenAI-style
```json
{
  "choices": [{
    "delta": {
      "content": "token here"
    }
  }]
}
```

### Option 3: Simple
```json
{
  "content": "token here",
  "is_thinking": false
}
```

**S·ª≠a parsing logic ƒë·ªÉ match v·ªõi format c·ªßa b·∫°n!**

---

## üö® **L∆∞u √ù Quan Tr·ªçng**

1. **Base URL**: Nh·ªõ set ƒë√∫ng base URL c·ªßa service
2. **Authentication**: Set API key n·∫øu c·∫ßn auth
3. **SSE Format**: Parse theo format c·ªßa service b·∫°n
4. **Function Format**: LLM ph·∫£i hi·ªÉu XML format ƒë·ªÉ call functions
5. **Conversation ID**: Provider t·ª± ƒë·ªông manage, nh∆∞ng c√≥ th·ªÉ custom

---

## üéä **Ready!**

CustomAPIProvider ƒë√£ s·∫µn s√†ng ƒë·ªÉ use v·ªõi service LLM c·ªßa b·∫°n!

**Next steps:**
1. ‚úÖ Configure provider v·ªõi base URL & API key
2. ‚úÖ Test v·ªõi simple chat
3. ‚úÖ Enable thinking mode trong UI
4. ‚úÖ Add function calling n·∫øu c·∫ßn
5. ‚úÖ Monitor token usage

---

*Provider Location:* `src/main/java/com/noteflix/pcm/llm/provider/CustomAPIProvider.java`  
*Examples:* `src/main/java/com/noteflix/pcm/llm/examples/CustomAPIUsageExample.java`  
*Build Status:* ‚úÖ SUCCESS (224 class files)

